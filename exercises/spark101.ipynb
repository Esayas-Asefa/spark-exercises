{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb209a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, expr\n",
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import asc, desc\n",
    "from vega_datasets import data\n",
    "from pyspark.sql.functions import month, year, quarter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d1ed1",
   "metadata": {},
   "source": [
    "Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "The name of the column should be language\n",
    "\n",
    "View the schema of the dataframe\n",
    "\n",
    "Output the shape of the dataframe\n",
    "\n",
    "Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40cd1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['python', 'sql', 'pyspark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3eb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = pd.DataFrame(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9977cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/30 16:28:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db513679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7697e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|      0|\n",
      "+-------+\n",
      "| python|\n",
      "|    sql|\n",
      "|pyspark|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7638c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"0\", \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c66945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|     sql|\n",
      "| pyspark|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12be1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c7de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4abfa64",
   "metadata": {},
   "source": [
    "Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "\n",
    "The 1999 audi a4 has a 4 cylinder engine.\n",
    "For each vehicle.\n",
    "\n",
    "Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2acb62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86c2f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbadcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data('mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "977eb27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd88b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea1fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db130f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
